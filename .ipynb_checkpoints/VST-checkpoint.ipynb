{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43265239-e20e-45e9-8742-05f6ba404ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/home/chenweilin/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append('./CMR-AI/mmaction/')\n",
    "sys.path.append('./CMR-AI/')\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from swinTransformer3D_origin import SwinTransformer3D\n",
    "from mutil_class_loss import FocalLoss, cal_auc\n",
    "from weighted_auc_f1 import get_weighted_auc_f1\n",
    "from load_dataset import ACDC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import SimpleITK as sitk\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "import nibabel as nib\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e2dcfa-ca3a-48f3-b248-3ef55cf05a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3214.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_class = 4\n",
    "funsion_model = SwinTransformer3D(num_class=num_class)\n",
    "\n",
    "phase = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f243e565-2372-4d11-98da-9a5e0a554e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if phase == 'train':\n",
    "    # _pretrained_dict = torch.load(r'../pretrained model/swin_base_patch244_window877_kinetics600_22k.pth')\n",
    "    _pretrained_dict = torch.load(r'./ACDC/organmnist3d/organmnist3d_250.pth')\n",
    "    pretrained_dict = {}\n",
    "    for k, v in _pretrained_dict['state_dict'].items():\n",
    "        if k.startswith('backbone.'):\n",
    "            new_key = k.replace('backbone.', '')\n",
    "        elif k.startswith('cls_head.'):\n",
    "            new_key = k.replace('cls_head.', '')\n",
    "        else:\n",
    "            new_key = k\n",
    "        pretrained_dict[new_key] = v\n",
    "else:\n",
    "    _pretrained_dict = torch.load(r'./train_model/VST/epoch_250.pth')\n",
    "    pretrained_dict = {}\n",
    "    for k, v in _pretrained_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            new_key = k.replace('module.', '')\n",
    "        elif k.startswith('cls_head.'):\n",
    "            new_key = k.replace('cls_head.', '')\n",
    "        else:\n",
    "            new_key = k\n",
    "        pretrained_dict[new_key] = v\n",
    "    \n",
    "model_dict = funsion_model.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.size() == model_dict[k].size()}\n",
    "model_dict.update(pretrained_dict)\n",
    "funsion_model.load_state_dict(pretrained_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d021bd5-6941-42e9-8874-3fe15c84efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./roi_processed/training/train_data.csv', encoding='GBK')\n",
    "test_data = pd.read_csv('./roi_processed/testing/test_data.csv', encoding='GBK')\n",
    "dummy_labels = ['HCM', 'RV', 'DCM', 'MINF']# ['HCM', 'DCM', 'MINF', 'RV', 'NOR'] # taken from paper\n",
    "train_data = train_data[train_data['Finding Labels'].isin(dummy_labels)]\n",
    "test_data = test_data[test_data['Finding Labels'].isin(dummy_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c29be464-2ea9-4bcf-8094-d22ca218dfa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding of Finding Labels to dummy_labels\n",
    "for label in dummy_labels:\n",
    "    train_data[label] = train_data['Finding Labels'].map(lambda result: 1.0 if label in result else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9357285b-ecf1-40ad-9ef5-7f7f4d490bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding of Finding Labels to dummy_labels\n",
    "for label in dummy_labels:\n",
    "    test_data[label] = test_data['Finding Labels'].map(lambda result: 1.0 if label in result else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "600a4135-e785-4364-b605-c2515eb40907",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['target_vector'] = train_data.apply(lambda target: [target[dummy_labels].values], 1).map(lambda target: target[0])\n",
    "\n",
    "test_data['target_vector'] = test_data.apply(lambda target: [target[dummy_labels].values], 1).map(lambda target: target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f4ecae2-6ef9-4e38-ba10-a785847dd3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size：\n",
      "HCM     20.0\n",
      "RV      20.0\n",
      "DCM     20.0\n",
      "MINF    20.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "clean_labels = train_data[dummy_labels].sum().sort_values(ascending= False) # get sorted value_count for clean labels\n",
    "print(f'train size：')\n",
    "print(clean_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b0d773-93fc-4ca7-8cf9-6f6194900603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size：\n",
      "HCM     10.0\n",
      "RV      10.0\n",
      "DCM     10.0\n",
      "MINF    10.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'test size：')\n",
    "clean_labels = test_data[dummy_labels].sum().sort_values(ascending= False) # get sorted value_count for clean labels\n",
    "print(clean_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a00694-9097-40a2-8de9-0cda171b89c7",
   "metadata": {},
   "source": [
    "## 训练开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a420aaea-5690-4458-b7cf-232de331180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.0005\n",
    "batch_size = 8\n",
    "max_epoch = 600\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    funsion_model = nn.DataParallel(funsion_model)\n",
    "\n",
    "funsion_model = funsion_model.cuda()\n",
    "fn_loss  = FocalLoss(device = device, gamma = 2.).to(device)\n",
    "cross_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(funsion_model.parameters(), lr=base_lr)\n",
    "\n",
    "train_acdc_data = ACDC(data=train_data, phase = 'train', img_size=(224, 224))\n",
    "train_data_loader = DataLoader(train_acdc_data, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "test_acdc_data = ACDC(data=test_data, phase = 'test', img_size=(224, 224))\n",
    "test_data_loader = DataLoader(test_acdc_data, batch_size=batch_size, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac16c78-cf32-4804-9e16-aa638f320ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./runs/VST-ACDC') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a1efda-3f38-4954-9bad-8e988ff116d6",
   "metadata": {},
   "source": [
    "### model train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d14b1ca-a396-4cb9-ab02-ccedcc23ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if phase == 'train':\n",
    "    import time\n",
    "    for epoch_num in range(0, max_epoch):\n",
    "        print(f\"--------> epoch_num: {epoch_num}\")\n",
    "        train_loader_nums = len(train_data_loader.dataset)\n",
    "        probs = np.zeros((train_loader_nums, num_class), dtype = np.float32)\n",
    "        gt    = np.zeros((train_loader_nums, num_class), dtype = np.float32)\n",
    "        k=0\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0.0\n",
    "        correct = 0.0\n",
    "        funsion_model.train()\n",
    "        train_batch_sitorch = 0.0\n",
    "        for train_data_batch, _, train_labels_batch in train_data_loader:\n",
    "            train_data_batch = train_data_batch.cuda()\n",
    "            train_labels_batch = train_labels_batch.cuda()\n",
    "            outputs, _ = funsion_model(train_data_batch)\n",
    "            outputs = outputs.reshape(outputs.shape[0], -1)\n",
    "            train_labels_batch = train_labels_batch.reshape(train_labels_batch.shape[0], -1)\n",
    "\n",
    "            probs[k: k + outputs.shape[0], :] = outputs.cpu().detach().numpy()\n",
    "            gt[   k: k + outputs.shape[0], :] = train_labels_batch.cpu().detach().numpy()\n",
    "            k += outputs.shape[0]\n",
    "\n",
    "            train_loss = cross_loss(outputs, train_labels_batch)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += train_loss\n",
    "            \n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            labels = torch.argmax(train_labels_batch, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "                        \n",
    "        auc = cal_auc(gt, probs)\n",
    "        print(f\"epoch_num {epoch_num} av train loss {total_train_loss}  train auc {auc} train acc {correct/k}\")  \n",
    "        \n",
    "        writer.add_scalars('Training Metrics', {\n",
    "            'Loss': total_train_loss,\n",
    "            'Accuracy': correct / train_loader_nums,\n",
    "            'AUC': auc,\n",
    "        }, epoch_num)\n",
    "        \n",
    "        end_time = time.time() \n",
    "        elapsed_time = end_time - start_time \n",
    "        print(f\"程序运行时间：{elapsed_time} 秒\")\n",
    "\n",
    "        lr_ = base_lr*(1-0.0009)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr_\n",
    "\n",
    "        save_interval = 25  \n",
    "        if (epoch_num + 1) % save_interval == 0:\n",
    "            save_mode_path = os.path.join('./train_model/VST', 'epoch_' + str(epoch_num+1) + '.pth')\n",
    "            torch.save(funsion_model.state_dict(), save_mode_path)\n",
    "            print(\"save model to {}\".format(save_mode_path))\n",
    "        test_interval = 25  # int(max_epoch/6)\n",
    "        if (epoch_num + 1) % test_interval == 0:\n",
    "            test_loader_nums = len(test_data_loader.dataset)\n",
    "            test_probs = np.zeros((test_loader_nums, num_class), dtype = np.float32)\n",
    "            test_gt    = np.zeros((test_loader_nums, num_class), dtype = np.float32)\n",
    "            test_k  =0\n",
    "            funsion_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for test_data_batch, _, test_label_batch in test_data_loader:\n",
    "                    test_data_batch = test_data_batch.cuda()\n",
    "                    test_label_batch = test_label_batch.cuda()\n",
    "                    test_outputs, _ = funsion_model(test_data_batch)\n",
    "                    test_outputs = test_outputs.reshape(test_outputs.shape[0], -1)           \n",
    "                    test_label_batch = test_label_batch.reshape(test_outputs.shape[0], -1)\n",
    "                    # storing model predictions for metric evaluat`ion \n",
    "                    test_probs[test_k: test_k + test_outputs.shape[0], :] = test_outputs.cpu().detach().numpy()\n",
    "                    test_gt[   test_k: test_k + test_outputs.shape[0], :] = test_label_batch.cpu().detach().numpy()\n",
    "                    test_k += test_outputs.shape[0]\n",
    "                test_label = np.argmax(test_gt, axis=1)\n",
    "                test_pred = np.argmax(test_probs, axis=1)\n",
    "                print(f\"auc: {cal_auc(test_gt, test_probs)} | acc: {np.sum(test_label==test_pred)/test_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00602c0e-3136-4a2d-a6c4-b4135e7c3301",
   "metadata": {},
   "source": [
    "### model eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6225ad6b-4733-4cc1-93c1-614d02f21285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "auc_list : [0.9400000000000001, 0.9933333333333333, 0.9566666666666668, 0.9366666666666668]\n",
      "weighted_auroc:  0.9566666666666668\n",
      "weighted_F1:  0.8519387236206458\n",
      "weight auc: [0.9566666666666668] ; weight acc : [0.85]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9666666666666668, 0.9833333333333334, 0.9633333333333334, 0.9266666666666667]\n",
      "weighted_auroc:  0.9600000000000001\n",
      "weighted_F1:  0.8519387236206458\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001] ; weight acc : [0.85, 0.85]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9633333333333333, 0.9866666666666667, 0.9666666666666668, 0.9500000000000001]\n",
      "weighted_auroc:  0.9666666666666668\n",
      "weighted_F1:  0.853250773993808\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001, 0.9666666666666668] ; weight acc : [0.85, 0.85, 0.8500000000000001]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9733333333333334, 0.9866666666666667, 0.9366666666666666, 0.9400000000000001]\n",
      "weighted_auroc:  0.9591666666666666\n",
      "weighted_F1:  0.8769138755980862\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001, 0.9666666666666668, 0.9591666666666666] ; weight acc : [0.85, 0.85, 0.8500000000000001, 0.875]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9733333333333334, 0.9933333333333333, 0.9600000000000001, 0.9633333333333334]\n",
      "weighted_auroc:  0.9725\n",
      "weighted_F1:  0.8760577915376677\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001, 0.9666666666666668, 0.9591666666666666, 0.9725] ; weight acc : [0.85, 0.85, 0.8500000000000001, 0.875, 0.875]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.97, 0.9866666666666667, 0.9666666666666667, 0.9433333333333334]\n",
      "weighted_auroc:  0.9666666666666667\n",
      "weighted_F1:  0.8519387236206458\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001, 0.9666666666666668, 0.9591666666666666, 0.9725, 0.9666666666666667] ; weight acc : [0.85, 0.85, 0.8500000000000001, 0.875, 0.875, 0.85]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9366666666666666, 0.9933333333333333, 0.9666666666666667, 0.9433333333333334]\n",
      "weighted_auroc:  0.96\n",
      "weighted_F1:  0.8519387236206458\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001, 0.9666666666666668, 0.9591666666666666, 0.9725, 0.9666666666666667, 0.96] ; weight acc : [0.85, 0.85, 0.8500000000000001, 0.875, 0.875, 0.85, 0.85]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9766666666666666, 0.9933333333333333, 0.97, 0.9733333333333334]\n",
      "weighted_auroc:  0.9783333333333333\n",
      "weighted_F1:  0.8760577915376677\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001, 0.9666666666666668, 0.9591666666666666, 0.9725, 0.9666666666666667, 0.96, 0.9783333333333333] ; weight acc : [0.85, 0.85, 0.8500000000000001, 0.875, 0.875, 0.85, 0.85, 0.875]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.95, 0.9833333333333334, 0.94, 0.9233333333333333]\n",
      "weighted_auroc:  0.9491666666666666\n",
      "weighted_F1:  0.8293128654970761\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001, 0.9666666666666668, 0.9591666666666666, 0.9725, 0.9666666666666667, 0.96, 0.9783333333333333, 0.9491666666666666] ; weight acc : [0.85, 0.85, 0.8500000000000001, 0.875, 0.875, 0.85, 0.85, 0.875, 0.8250000000000001]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9800000000000001, 0.9933333333333333, 0.9766666666666667, 0.9366666666666666]\n",
      "weighted_auroc:  0.9716666666666667\n",
      "weighted_F1:  0.8519387236206458\n",
      "weight auc: [0.9566666666666668, 0.9600000000000001, 0.9666666666666668, 0.9591666666666666, 0.9725, 0.9666666666666667, 0.96, 0.9783333333333333, 0.9491666666666666, 0.9716666666666667] ; weight acc : [0.85, 0.85, 0.8500000000000001, 0.875, 0.875, 0.85, 0.85, 0.875, 0.8250000000000001, 0.85]\n"
     ]
    }
   ],
   "source": [
    "total_acc_list = []\n",
    "total_auroc_list = []\n",
    "\n",
    "total_weight_auroc_list = []\n",
    "total_weight_acc_list = []\n",
    "### 模型验证\n",
    "for i in range(10):\n",
    "    test_loader_nums = len(test_data_loader.dataset)\n",
    "    test_probs = np.zeros((test_loader_nums, len(dummy_labels)), dtype = np.float32)\n",
    "    test_gt    = np.zeros((test_loader_nums, len(dummy_labels)), dtype = np.float32)\n",
    "    test_k  =0\n",
    "    funsion_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_data_batch, _, test_label_batch in test_data_loader:\n",
    "            test_data_batch = test_data_batch.cuda()\n",
    "            test_label_batch = test_label_batch.cuda()\n",
    "            test_outputs, _ = funsion_model(test_data_batch.cuda())\n",
    "            test_outputs = test_outputs.reshape(test_outputs.shape[0], -1)           \n",
    "            test_label_batch = test_label_batch.reshape(test_outputs.shape[0], -1)\n",
    "            test_probs[test_k: test_k + test_outputs.shape[0], :] = test_outputs.cpu().detach().numpy()\n",
    "            test_gt[   test_k: test_k + test_outputs.shape[0], :] = test_label_batch.cpu().detach().numpy()\n",
    "            test_k += test_outputs.shape[0]\n",
    "        test_label = np.argmax(test_gt, axis=1)\n",
    "        test_pred = np.argmax(test_probs, axis=1)\n",
    "        weight_auc, auc_list = get_weighted_auc_f1(test_probs, test_pred, test_label)\n",
    "\n",
    "        cm = confusion_matrix(test_label, test_pred)\n",
    "        dataset_list = [10, 10, 10, 10]  # , 7\n",
    "        acc_list = []\n",
    "        weighted_acc = 0.0\n",
    "        for i in range(len(dataset_list)):\n",
    "            weight = dataset_list[i] / sum(dataset_list)\n",
    "            correct = cm[i][i]\n",
    "            acc = float(correct) / dataset_list[i]\n",
    "            acc_list.append(acc)\n",
    "            weighted_acc += weight*acc \n",
    "        \n",
    "        total_auroc_list.append(auc_list)\n",
    "        total_acc_list.append(acc_list)\n",
    "        total_weight_auroc_list.append(weight_auc)\n",
    "        total_weight_acc_list.append(weighted_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc9b6a7f-3286-4e7e-951b-7bdd67836465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n",
      "0.9629999999999999 0.014640127503998509\n",
      "0.9893333333333334 0.004163331998932223\n",
      "0.9603333333333334 0.012151817422372141\n",
      "0.9436666666666668 0.014564034849968988\n"
     ]
    }
   ],
   "source": [
    "auc_arr = np.array(total_auroc_list)\n",
    "print(auc_arr.shape)\n",
    "for i in range(auc_arr.shape[-1]):\n",
    "    auc_arr_cls = auc_arr[:, i]\n",
    "    mean = np.mean(auc_arr_cls)\n",
    "    std = np.std(auc_arr_cls)\n",
    "    print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1ea0b8-9e77-4798-b9e2-7617eb427853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n",
      "0.9 0.0\n",
      "0.8799999999999999 0.039999999999999994\n",
      "0.71 0.030000000000000023\n",
      "0.93 0.04582575694955839\n"
     ]
    }
   ],
   "source": [
    "acc_arr = np.array(total_acc_list)\n",
    "print(acc_arr.shape)\n",
    "for i in range(auc_arr.shape[-1]):\n",
    "    acc_arr_cls = acc_arr[:, i]\n",
    "    mean = np.mean(acc_arr_cls)\n",
    "    std = np.std(acc_arr_cls)\n",
    "    print(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3bd11-b973-4e21-90b6-fb76fec3f45f",
   "metadata": {},
   "source": [
    "### end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

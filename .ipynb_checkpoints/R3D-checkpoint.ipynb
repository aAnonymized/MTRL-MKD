{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9398ce15-1861-4a36-aede-6a99f432f96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/home/chenweilin/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append('./R3D/models')\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from resnet2p1d import ResNet, Bottleneck\n",
    "from mutil_class_loss import FocalLoss, cal_auc\n",
    "from weighted_auc_f1 import get_weighted_auc_f1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import SimpleITK as sitk\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "from load_dataset import ACDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b7ef9e-371c-4545-879a-1025284565ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dummy_labels =  ['HCM', 'RV', 'DCM', 'MINF']\n",
    "num_class = len(dummy_labels)\n",
    "model = ResNet(block=Bottleneck, layers=[3, 4, 6, 3], block_inplanes=[64, 128, 256, 512], n_classes=700, cls_num=num_class)\n",
    "\n",
    "phase = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459eaaa2-24e4-4aef-92bb-0353c827caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if phase == 'train':\n",
    "    checkpoint = torch.load(r'./r2p1d50_K_200ep.pth', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "else:\n",
    "    checkpoint = torch.load(r'./train_model/R3D/epoch_100.pth')\n",
    "    model.load_state_dict(checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db504166-2860-4c3f-ba61-4e57b7e85ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./roi_processed/training/train_data.csv', encoding='GBK')\n",
    "test_data = pd.read_csv('./roi_processed/testing/test_data.csv', encoding='GBK')\n",
    "\n",
    "train_data = train_data[train_data['Finding Labels'].isin(dummy_labels)]\n",
    "test_data = test_data[test_data['Finding Labels'].isin(dummy_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6c8bb5-f98e-4de8-ac97-8e2dd149cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding of Finding Labels to dummy_labels\n",
    "for label in dummy_labels:\n",
    "    train_data[label] = train_data['Finding Labels'].map(lambda result: 1.0 if label in result else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b8698b-e992-49a2-812d-8cea1c0a74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding of Finding Labels to dummy_labels\n",
    "for label in dummy_labels:\n",
    "    test_data[label] = test_data['Finding Labels'].map(lambda result: 1.0 if label in result else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea6e26ae-0d34-4c9e-a65d-003993816e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['target_vector'] = train_data.apply(lambda target: [target[dummy_labels].values], 1).map(lambda target: target[0])\n",
    "test_data['target_vector'] = test_data.apply(lambda target: [target[dummy_labels].values], 1).map(lambda target: target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec35d990-0f18-434d-839a-5d308e766653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size：\n",
      "HCM     20.0\n",
      "RV      20.0\n",
      "DCM     20.0\n",
      "MINF    20.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "clean_labels = train_data[dummy_labels].sum().sort_values(ascending= False) # get sorted value_count for clean labels\n",
    "print(f'train size：')\n",
    "print(clean_labels) # view tabular results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01694be2-0f01-4c57-83f7-1d86052f6256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test zise：\n",
      "HCM     10.0\n",
      "RV      10.0\n",
      "DCM     10.0\n",
      "MINF    10.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'test zise：')\n",
    "clean_labels = test_data[dummy_labels].sum().sort_values(ascending= False) # get sorted value_count for clean labels\n",
    "print(clean_labels) # view tabular results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39760608-ccb5-4a04-9dd9-fdf2cce1feb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "base_lr = 0.0005\n",
    "batch_size = 8\n",
    "max_epoch = 200\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device {device}')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "model = model.to(device)\n",
    "fn_loss  = FocalLoss(device = device, gamma = 2.).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=base_lr)\n",
    "\n",
    "train_acdc_data = ACDC(data=train_data, phase = 'train', img_size=(224, 224))\n",
    "train_data_loader = DataLoader(train_acdc_data, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "test_acdc_data = ACDC(data=test_data, phase = 'test', img_size=(224, 224))\n",
    "test_data_loader = DataLoader(test_acdc_data, batch_size=batch_size, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "910ca3c9-f12b-45c6-aa7b-12f771362d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=f'./runs/R3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d200efe3-ca46-4ee7-826b-5c5865225fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Was asked to gather along dimension 0, but all input tensors were scalars\")\n",
    "\n",
    "if phase == 'train':\n",
    "    import time\n",
    "    for epoch_num in range(0, max_epoch):\n",
    "        print(f\"--------> epoch_num: {epoch_num}\")\n",
    "        train_loader_nums = len(train_data_loader.dataset)\n",
    "        probs = np.zeros((train_loader_nums, num_class), dtype = np.float32)\n",
    "        gt    = np.zeros((train_loader_nums, num_class), dtype = np.float32)\n",
    "        k=0\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0.0\n",
    "        correct = 0.0\n",
    "        model.train()\n",
    "        for train_data_batch, batch_finding, train_labels_batch in train_data_loader:\n",
    "            train_data_batch = train_data_batch.to(device)\n",
    "            train_labels_batch = train_labels_batch.to(device)\n",
    "            outputs = model(train_data_batch)\n",
    "            outputs = outputs.reshape(outputs.shape[0], -1) \n",
    "            train_labels_batch = train_labels_batch.reshape(train_labels_batch.shape[0], -1)\n",
    "            probs[k: k + outputs.shape[0], :] = outputs.cpu().detach().numpy()\n",
    "            gt[   k: k + outputs.shape[0], :] = train_labels_batch.cpu().detach().numpy()\n",
    "            k += outputs.shape[0]\n",
    "\n",
    "            train_loss = fn_loss(outputs, train_labels_batch)\n",
    "            total_train_loss += train_loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            labels = torch.argmax(train_labels_batch, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        auc = cal_auc(gt, probs)\n",
    "        print(f\"epoch_num {epoch_num} av train loss {total_train_loss}  train auc {auc} train acc {correct/train_loader_nums}\")  \n",
    "        \n",
    "        writer.add_scalars('Training Metrics', {\n",
    "            'Loss': total_train_loss / train_loader_nums*20,\n",
    "            'Accuracy': correct / train_loader_nums,\n",
    "            'AUC': auc,\n",
    "        }, epoch_num)\n",
    "        \n",
    "        end_time = time.time() \n",
    "        elapsed_time = end_time - start_time \n",
    "        print(f\"程序运行时间：{elapsed_time} 秒\")\n",
    "\n",
    "        lr_ = base_lr*(1-0.0009)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr_\n",
    "\n",
    "        save_interval = 25 \n",
    "        if (epoch_num + 1) % save_interval == 0:\n",
    "            save_mode_path = os.path.join(f'./train_model/R3D', 'epoch_' + str(epoch_num+1) + '.pth')\n",
    "            torch.save(model.state_dict(), save_mode_path)\n",
    "            print(\"save model to {}\".format(save_mode_path))\n",
    "        test_interval = 25\n",
    "        if (epoch_num + 1) % test_interval == 0:\n",
    "            test_loader_nums = len(test_data_loader.dataset)\n",
    "            test_probs = np.zeros((test_loader_nums, num_class), dtype = np.float32)\n",
    "            test_gt    = np.zeros((test_loader_nums, num_class), dtype = np.float32)\n",
    "            test_k  =0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for test_data_batch, _, test_label_batch in test_data_loader:\n",
    "                    test_data_batch = test_data_batch.to(\"cuda:0\")\n",
    "                    test_label_batch = test_label_batch.to(\"cuda:0\")\n",
    "                    test_outputs = model(test_data_batch)\n",
    "                    test_outputs = test_outputs.reshape(test_outputs.shape[0], -1)           \n",
    "                    test_label_batch = test_label_batch.reshape(test_outputs.shape[0], -1)\n",
    "                    test_probs[test_k: test_k + test_outputs.shape[0], :] = test_outputs.cpu().detach().numpy()\n",
    "                    test_gt[   test_k: test_k + test_outputs.shape[0], :] = test_label_batch.cpu().detach().numpy()\n",
    "                    test_k += test_outputs.shape[0]\n",
    "                test_label = np.argmax(test_gt, axis=1)\n",
    "                test_pred = np.argmax(test_probs, axis=1)\n",
    "                print(f\"auc: {cal_auc(test_gt, test_probs)} | acc: {np.sum(test_label==test_pred)/test_loader_nums}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c901f-d8c7-4a34-9d63-02e9a35c4d3f",
   "metadata": {},
   "source": [
    "内存：11102MiB\\\n",
    "5.2 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5778eb58-8f6a-45fd-9f5d-216629d1507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8112da9-66e1-4798-a55c-985aec8e4bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "auc_list : [0.9333333333333333, 0.9166666666666667, 0.9633333333333334, 0.8066666666666666]\n",
      "weighted_auroc:  0.905\n",
      "weighted_F1:  0.825139842359522\n",
      "weight auc: [0.905] ; weight acc : [0.825]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9533333333333334, 0.91, 0.9566666666666668, 0.8400000000000001]\n",
      "weighted_auroc:  0.915\n",
      "weighted_F1:  0.7234299516908211\n",
      "weight auc: [0.905, 0.915] ; weight acc : [0.825, 0.7249999999999999]\n",
      "--------------------------------------------------\n",
      "auc_list : [0.9666666666666667, 0.9333333333333333, 0.9199999999999999, 0.7666666666666666]\n",
      "weighted_auroc:  0.8966666666666666\n",
      "weighted_F1:  0.7813131313131314\n",
      "weight auc: [0.905, 0.915, 0.8966666666666666] ; weight acc : [0.825, 0.7249999999999999, 0.7750000000000001]\n"
     ]
    }
   ],
   "source": [
    "total_acc_list = []\n",
    "total_auroc_list = []\n",
    "\n",
    "total_weight_auroc_list = []\n",
    "total_weight_acc_list = []\n",
    "### 模型验证\n",
    "for i in range(10):\n",
    "    test_loader_nums = len(test_data_loader.dataset)\n",
    "    test_probs = np.zeros((test_loader_nums, len(dummy_labels)), dtype = np.float32)\n",
    "    test_gt    = np.zeros((test_loader_nums, len(dummy_labels)), dtype = np.float32)\n",
    "    test_k  =0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_data_batch, _, test_label_batch in test_data_loader:\n",
    "            test_data_batch = test_data_batch.cuda()\n",
    "            test_label_batch = test_label_batch.cuda()\n",
    "            test_outputs = model(test_data_batch.cuda())\n",
    "            test_outputs = test_outputs.reshape(test_outputs.shape[0], -1)           \n",
    "            test_label_batch = test_label_batch.reshape(test_outputs.shape[0], -1)\n",
    "            test_probs[test_k: test_k + test_outputs.shape[0], :] = test_outputs.cpu().detach().numpy()\n",
    "            test_gt[   test_k: test_k + test_outputs.shape[0], :] = test_label_batch.cpu().detach().numpy()\n",
    "            test_k += test_outputs.shape[0]\n",
    "        test_label = np.argmax(test_gt, axis=1)\n",
    "        test_pred = np.argmax(test_probs, axis=1)\n",
    "        weight_auc, auc_list = get_weighted_auc_f1(test_probs, test_pred, test_label)\n",
    "\n",
    "        cm = confusion_matrix(test_label, test_pred)\n",
    "        dataset_list = [10, 10, 10, 10]  # , 7\n",
    "        acc_list = []\n",
    "        weighted_acc = 0.0\n",
    "        for i in range(len(dataset_list)):\n",
    "            weight = dataset_list[i] / sum(dataset_list)\n",
    "            correct = cm[i][i]\n",
    "            acc = float(correct) / dataset_list[i]\n",
    "            acc_list.append(acc)\n",
    "            weighted_acc += weight*acc \n",
    "        \n",
    "        total_auroc_list.append(auc_list)\n",
    "        total_acc_list.append(acc_list)\n",
    "        total_weight_auroc_list.append(weight_auc)\n",
    "        total_weight_acc_list.append(weighted_acc)\n",
    "    print(f'weight auc: {total_weight_auroc_list} ; weight acc : {total_weight_acc_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1927314-ae3d-424e-a46f-b55582c93b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_arr = np.array(total_auroc_list)\n",
    "print(auc_arr.shape)\n",
    "for i in range(auc_arr.shape[-1]):\n",
    "    auc_arr_cls = auc_arr[:, i]\n",
    "    mean = np.mean(auc_arr_cls)\n",
    "    std = np.std(auc_arr_cls)\n",
    "    print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128383af-a1da-4a59-bf92-21ddeb180684",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_arr = np.array(total_acc_list)\n",
    "print(acc_arr.shape)\n",
    "for i in range(auc_arr.shape[-1]):\n",
    "    acc_arr_cls = acc_arr[:, i]\n",
    "    mean = np.mean(acc_arr_cls)\n",
    "    std = np.std(acc_arr_cls)\n",
    "    print(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34352c-ce0f-424c-be88-a3f6121c7202",
   "metadata": {},
   "source": [
    "### end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
